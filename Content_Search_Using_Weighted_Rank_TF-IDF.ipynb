{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d44c748",
   "metadata": {},
   "source": [
    "# Content Search Using Weighted Rank TF-IDF\n",
    "### `Data Souce:-` I have scrapped data from https://clinicaltrials.gov/ website & lodaded into MySQL DB.\n",
    "### [View Web Scraper & Load Data To MySQL ETL Notebook](https://nbviewer.org/github/pranabkumarpaul/Web_Scraper_And_ETL/blob/main/Web_Scraper_%26_Load_To_MySQL_ETL.ipynb)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af4e96",
   "metadata": {},
   "source": [
    "## Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f915507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip3 install num2words==0.5.10\n",
    "# import nltk\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2230ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59297018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from num2words import num2words\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8a894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8db4f",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ca3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MySQL DB Info\n",
    "Schema = \"clinical_studies\"\n",
    "Table = \"land_clinical_trials\"\n",
    "SQL_CLM = 'Row_No , NCT_Id , `Condition` , Study_Title , Study_Type'\n",
    "\n",
    "MySQL_Endpoint = \"127.0.0.1\"\n",
    "MySQL_Port = \"3306\"\n",
    "MySQL_UserName = \"root\"\n",
    "MySQL_Password = \"MySql@1234\"\n",
    "MySQL_DataBase = \"clinical_studies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ea8a9",
   "metadata": {},
   "source": [
    "## Create MySQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f557191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MySQL_Connection = pymysql.connect(host= MySQL_Endpoint, \n",
    "                                   user= MySQL_UserName, \n",
    "                                   password= MySQL_Password, \n",
    "                                   db= MySQL_DataBase)\n",
    "\n",
    "MySQL_Cursor = MySQL_Connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029d57a",
   "metadata": {},
   "source": [
    "## Read Data From MySQL DB & Remove Duplicate Rows If Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9b87dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before deleting duplicate values:- (20000, 5)\n",
      "Shape after deleting duplicate values:- (20000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_No</th>\n",
       "      <th>NCT_Id</th>\n",
       "      <th>`Condition`</th>\n",
       "      <th>Study_Title</th>\n",
       "      <th>Study_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT05516706</td>\n",
       "      <td>Sports Physical Therapy</td>\n",
       "      <td>Comparison of Dynamic Stretching and Plyometric Push up Training on Upper Body Performance Tests in Cricketers</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NCT05516693</td>\n",
       "      <td>Mastication Disorder, Swallowing Disorder, Orofacial Dyskinesia</td>\n",
       "      <td>Chewing, Swallowing and Orofacial Motricity in Severe Obese</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NCT05516680</td>\n",
       "      <td>Poststroke Depression, Healthy</td>\n",
       "      <td>Effects and Central Mechanism of Electroacupuncture and MRInavigated rTMS for PSD</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row_No       NCT_Id   \\\n",
       "0        1  NCT05516706   \n",
       "1        2  NCT05516693   \n",
       "2        3  NCT05516680   \n",
       "\n",
       "                                                      `Condition`   \\\n",
       "0                                          Sports Physical Therapy   \n",
       "1  Mastication Disorder, Swallowing Disorder, Orofacial Dyskinesia   \n",
       "2                                   Poststroke Depression, Healthy   \n",
       "\n",
       "                                                                                                     Study_Title   \\\n",
       "0  Comparison of Dynamic Stretching and Plyometric Push up Training on Upper Body Performance Tests in Cricketers   \n",
       "1                                                     Chewing, Swallowing and Orofacial Motricity in Severe Obese   \n",
       "2                               Effects and Central Mechanism of Electroacupuncture and MRInavigated rTMS for PSD   \n",
       "\n",
       "       Study_Type  \n",
       "0  Interventional  \n",
       "1  Interventional  \n",
       "2  Interventional  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MySQL_Cursor.execute(f\"Select {SQL_CLM} from {Schema}.{Table}\")\n",
    "SQL_Row = MySQL_Cursor.fetchall()\n",
    "\n",
    "MySQL_Cursor.close()\n",
    "MySQL_Connection.close()\n",
    "\n",
    "Raw_Data = pd.DataFrame(SQL_Row, columns= SQL_CLM.split(\",\"))\n",
    "del SQL_Row\n",
    "\n",
    "print(f\"Shape before deleting duplicate values:- {Raw_Data.shape}\")\n",
    "\n",
    "Raw_Data.drop_duplicates()\n",
    "\n",
    "print(f\"Shape after deleting duplicate values:- {Raw_Data.shape}\")\n",
    "\n",
    "Raw_Data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da25c5f",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5669b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Row_No         20000 non-null  int64 \n",
      " 1    NCT_Id        20000 non-null  object\n",
      " 2    `Condition`   20000 non-null  object\n",
      " 3    Study_Title   20000 non-null  object\n",
      " 4    Study_Type    20000 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "Raw_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab23f0c",
   "metadata": {},
   "source": [
    "- ### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1748d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_No</th>\n",
       "      <th>NCT_Id</th>\n",
       "      <th>`Condition`</th>\n",
       "      <th>Study_Title</th>\n",
       "      <th>Study_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19428</td>\n",
       "      <td>12841</td>\n",
       "      <td>19367</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NCT05281497</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Trial of device that is not approved or cleared by the U.S. FDA</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>219</td>\n",
       "      <td>61</td>\n",
       "      <td>14950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5773.647028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5000.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15000.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Row_No       NCT_Id   `Condition`   \\\n",
       "count   20000.000000        20000         20000   \n",
       "unique           NaN        19428         12841   \n",
       "top              NaN  NCT05281497       Healthy   \n",
       "freq             NaN            2           219   \n",
       "mean    10000.500000          NaN           NaN   \n",
       "std      5773.647028          NaN           NaN   \n",
       "min         1.000000          NaN           NaN   \n",
       "25%      5000.750000          NaN           NaN   \n",
       "50%     10000.500000          NaN           NaN   \n",
       "75%     15000.250000          NaN           NaN   \n",
       "max     20000.000000          NaN           NaN   \n",
       "\n",
       "                                                           Study_Title   \\\n",
       "count                                                             20000   \n",
       "unique                                                            19367   \n",
       "top     Trial of device that is not approved or cleared by the U.S. FDA   \n",
       "freq                                                                 61   \n",
       "mean                                                                NaN   \n",
       "std                                                                 NaN   \n",
       "min                                                                 NaN   \n",
       "25%                                                                 NaN   \n",
       "50%                                                                 NaN   \n",
       "75%                                                                 NaN   \n",
       "max                                                                 NaN   \n",
       "\n",
       "            Study_Type  \n",
       "count            20000  \n",
       "unique               4  \n",
       "top     Interventional  \n",
       "freq             14950  \n",
       "mean               NaN  \n",
       "std                NaN  \n",
       "min                NaN  \n",
       "25%                NaN  \n",
       "50%                NaN  \n",
       "75%                NaN  \n",
       "max                NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Raw_Data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d03bc",
   "metadata": {},
   "source": [
    "- ### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207e7202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row_No           0\n",
       " NCT_Id          0\n",
       " `Condition`     0\n",
       " Study_Title     0\n",
       " Study_Type      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Raw_Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ba886",
   "metadata": {},
   "source": [
    "- ### Columns Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523a75ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Row_No', 'NCT_Id', 'Condition', 'Study_Title', 'Study_Type']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_No</th>\n",
       "      <th>NCT_Id</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Study_Title</th>\n",
       "      <th>Study_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT05516706</td>\n",
       "      <td>Sports Physical Therapy</td>\n",
       "      <td>Comparison of Dynamic Stretching and Plyometric Push up Training on Upper Body Performance Tests in Cricketers</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NCT05516693</td>\n",
       "      <td>Mastication Disorder, Swallowing Disorder, Orofacial Dyskinesia</td>\n",
       "      <td>Chewing, Swallowing and Orofacial Motricity in Severe Obese</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NCT05516680</td>\n",
       "      <td>Poststroke Depression, Healthy</td>\n",
       "      <td>Effects and Central Mechanism of Electroacupuncture and MRInavigated rTMS for PSD</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row_No       NCT_Id  \\\n",
       "0       1  NCT05516706   \n",
       "1       2  NCT05516693   \n",
       "2       3  NCT05516680   \n",
       "\n",
       "                                                         Condition  \\\n",
       "0                                          Sports Physical Therapy   \n",
       "1  Mastication Disorder, Swallowing Disorder, Orofacial Dyskinesia   \n",
       "2                                   Poststroke Depression, Healthy   \n",
       "\n",
       "                                                                                                      Study_Title  \\\n",
       "0  Comparison of Dynamic Stretching and Plyometric Push up Training on Upper Body Performance Tests in Cricketers   \n",
       "1                                                     Chewing, Swallowing and Orofacial Motricity in Severe Obese   \n",
       "2                               Effects and Central Mechanism of Electroacupuncture and MRInavigated rTMS for PSD   \n",
       "\n",
       "       Study_Type  \n",
       "0  Interventional  \n",
       "1  Interventional  \n",
       "2  Interventional  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Column = []\n",
    "\n",
    "for Each_Col in Raw_Data.columns:\n",
    "    New_Column.append(Each_Col.strip().replace(\"`\",\"\"))\n",
    "    \n",
    "print(New_Column)\n",
    "\n",
    "Raw_Data.columns = New_Column\n",
    "\n",
    "Raw_Data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85ac2a",
   "metadata": {},
   "source": [
    "## Saving The Data As A Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "410aa82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_Data.to_pickle(\"Raw_Data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665301b5",
   "metadata": {},
   "source": [
    "## Total Length Of The DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bea46861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_Row = len(Raw_Data)\n",
    "Total_Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85526438",
   "metadata": {},
   "source": [
    "## UDF - Function To Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25954414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Processor(Data_):\n",
    "    import re\n",
    "    \n",
    "    ### To Lower Case\n",
    "    Data_ = Data_.lower()\n",
    "    \n",
    "    ### Removing All The Special Characters or Punctuation\n",
    "    Data_ = re.sub(r'[!|\\|\"|#|$|%|&|(|)|*|+|-|.|/|:|;|<|=|>|?|@|[|]|^|_|`|{|}|~|\\n]' , r'' , Data_)\n",
    "    \n",
    "    ### Removing Stop Words & Lemmatisation\n",
    "    stop_words_ = stopwords.words('english')\n",
    "    Word_Lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    All_Words = word_tokenize(Data_)\n",
    "    \n",
    "    New_Text = \"\"\n",
    "    for Each_Word in All_Words:\n",
    "        if Each_Word not in stop_words_ and len(Each_Word) > 1:\n",
    "            Lemmatize_Word = Word_Lemmatizer.lemmatize(Each_Word)\n",
    "            New_Text = New_Text + \" \" + Lemmatize_Word\n",
    "            \n",
    "    ### Remove Apostrophe & RETURN\n",
    "    return New_Text.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5657a",
   "metadata": {},
   "source": [
    "## Extracting Informative Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da7a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Row Number- 19999\n",
      "\n",
      "Condition Column - \n",
      "['addiction', 'opiate']\n",
      "\n",
      "Study_Title Column - \n",
      "['comparison', 'different', 'psychotherapy', 'intervention', 'regarding', 'effect', 'substance', 'craving']\n"
     ]
    }
   ],
   "source": [
    "Processed_Condition = []\n",
    "Processed_Study_Title = []\n",
    "\n",
    "for Each_Row in range(Total_Row):\n",
    "    Processed_Condition.append(word_tokenize(str(Data_Processor(Data_=Raw_Data['Condition'][Each_Row]))))\n",
    "    Processed_Study_Title.append(word_tokenize(str(Data_Processor(Data_=Raw_Data['Study_Title'][Each_Row]))))\n",
    "\n",
    "### Last Row Number\n",
    "print(f\"Last Row Number- {Each_Row}\\n\")\n",
    "print(f\"Condition Column - \\n{Processed_Condition[Each_Row]}\\n\")\n",
    "print(f\"Study_Title Column - \\n{Processed_Study_Title[Each_Row]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b03f2f",
   "metadata": {},
   "source": [
    "## Calculating Occurrence Of The Word In Entire Document\n",
    "- #### Entire Document = Processed_Condition + Processed_Study_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b8786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words In Word_Frequency_In_Entire_Document Vocabulary:- 23619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Word_Frequency_In_Entire_Document = {}\n",
    "\n",
    "for Each_Row in range(Total_Row):\n",
    "    \n",
    "    for Each_Word in Processed_Condition[Each_Row]:\n",
    "        \n",
    "        if Each_Word not in Word_Frequency_In_Entire_Document.keys():\n",
    "            Word_Frequency_In_Entire_Document[Each_Word] = 1\n",
    "        else:\n",
    "            Word_Frequency_In_Entire_Document[Each_Word] += 1\n",
    "            \n",
    "    for Each_Word in Processed_Study_Title[Each_Row]:\n",
    "        \n",
    "        if Each_Word not in Word_Frequency_In_Entire_Document.keys():\n",
    "            Word_Frequency_In_Entire_Document[Each_Word] = 1\n",
    "        else:\n",
    "            Word_Frequency_In_Entire_Document[Each_Word] += 1\n",
    "            \n",
    "Total_Vocabulary_In_Entire_Document = len(Word_Frequency_In_Entire_Document)\n",
    "print(f\"Total Words In Word_Frequency_In_Entire_Document Vocabulary:- {Total_Vocabulary_In_Entire_Document}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f757f",
   "metadata": {},
   "source": [
    "## Sample Words In Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea9112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sport', 'physical', 'therapy', 'comparison', 'dynamic']\n",
      "['optic', 'thc', 'neuroinflammatory', 'cannabidiol', 'tetrahydrocannabinol']\n"
     ]
    }
   ],
   "source": [
    "Vocabulary_Words = [key for key in Word_Frequency_In_Entire_Document.keys()]\n",
    "print(Vocabulary_Words[:5])\n",
    "print(Vocabulary_Words[1000:1005])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d45a45",
   "metadata": {},
   "source": [
    "## Occurrence Of A Sample Word - `\"cancer\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eae7a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4503"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Frequency_In_Entire_Document['cancer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dffe407",
   "metadata": {},
   "source": [
    "## Calculating TF-IDF For Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6daf07ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Word & TF-IDF Value - \n",
      "\n",
      "{(0, 'physical'): 1.3419339231688436, (0, 'sport'): 1.9363976630213564, (0, 'therapy'): 0.925816759329015, (1, 'disorder'): 0.8550998004068601, (1, 'dyskinesia'): 1.2509403797479663}\n"
     ]
    }
   ],
   "source": [
    "Doc_No = 0\n",
    "\n",
    "TF_IDF_Condition = {}\n",
    "\n",
    "for Each_Row in range(Total_Row):\n",
    "    \n",
    "    Words = Processed_Condition[Each_Row]\n",
    "    Counter_ = Counter(Words)\n",
    "    Words_Count = len(Words)\n",
    "    \n",
    "\n",
    "    for Each_word in np.unique(Words):\n",
    "        \n",
    "        TF = Counter_[Each_word] / Words_Count\n",
    "        Word_Frequency = Word_Frequency_In_Entire_Document[Each_word]\n",
    "        IDF = np.log( ( Total_Row + 1 ) / ( Word_Frequency + 1 ) ) # Numerator Is Added 1 To Avoid Negative Values\n",
    "        \n",
    "        TF_IDF_Condition[Doc_No , Each_word] = TF * IDF\n",
    "        \n",
    "    Doc_No += 1\n",
    "    \n",
    "print(f\"Sample Word & TF-IDF Value - \\n\\n{dict(list(TF_IDF_Condition.items())[0: 5])}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817db807",
   "metadata": {},
   "source": [
    "## Calculating TF-IDF For Study_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f82dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Word & TF-IDF Value - \n",
      "\n",
      "{(0, 'body'): 0.41378903798273664, (0, 'comparison'): 0.3637185652622549, (0, 'cricketer'): 0.8373082155205659, (0, 'dynamic'): 0.5563043561243554, (0, 'performance'): 0.39003722226346355}\n"
     ]
    }
   ],
   "source": [
    "Doc_No = 0\n",
    "\n",
    "TF_IDF_Study_Title = {}\n",
    "\n",
    "for Each_Row in range(Total_Row):\n",
    "    \n",
    "    Words = Processed_Study_Title[Each_Row]\n",
    "    Counter_ = Counter(Words)\n",
    "    Words_Count = len(Words)\n",
    "    \n",
    "    for Each_word in np.unique(Words):\n",
    "        \n",
    "        TF = Counter_[Each_word] / Words_Count\n",
    "        Word_Frequency = Word_Frequency_In_Entire_Document[Each_word]\n",
    "        IDF = np.log( ( Total_Row + 1 ) / ( Word_Frequency + 1 ) ) # Numerator Is Added 1 To Avoid Negative Values\n",
    "        \n",
    "        TF_IDF_Study_Title[Doc_No , Each_word] = TF * IDF\n",
    "        \n",
    "    Doc_No += 1\n",
    "    \n",
    "print(f\"Sample Word & TF-IDF Value - \\n\\n{dict(list(TF_IDF_Study_Title.items())[0: 5])}\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ded22e",
   "metadata": {},
   "source": [
    "## Merging Both TF-IDF (TF_IDF_Condition , TF_IDF_Study_Title) By Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64825e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = 0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c55b7a",
   "metadata": {},
   "source": [
    "- #### Multiply The Entire TF_IDF_Condition With The Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22a44aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Word & TF-IDF Value - \n",
      "\n",
      "{(0, 'physical'): 0.5367735692675375, (0, 'sport'): 0.7745590652085426, (0, 'therapy'): 0.37032670373160603, (1, 'disorder'): 0.34203992016274404, (1, 'dyskinesia'): 0.5003761518991866}\n"
     ]
    }
   ],
   "source": [
    "for i in TF_IDF_Condition:\n",
    "    TF_IDF_Condition[i] *= Weights\n",
    "    \n",
    "print(f\"Sample Word & TF-IDF Value - \\n\\n{dict(list(TF_IDF_Condition.items())[0: 5])}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c512bb",
   "metadata": {},
   "source": [
    "- #### Iterate The Words in Study_Title & Replace The Value Of Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3096b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in TF_IDF_Study_Title:\n",
    "    TF_IDF_Condition[i] = TF_IDF_Study_Title[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d119e14",
   "metadata": {},
   "source": [
    "## Saving The Dictionary As A Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f34b9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"TF_IDF_Condition_PKL.pkl\", \"wb\") as TF_IDF_S_C_PKL:\n",
    "    pickle.dump(TF_IDF_Condition, TF_IDF_S_C_PKL , protocol= pickle.HIGHEST_PROTOCOL)\n",
    "TF_IDF_S_C_PKL.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633251a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a11c9bab",
   "metadata": {},
   "source": [
    "# <br><br>UDF - Final Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d302c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Best_Match_Records(String_To_Search , Records_To_Show = 5):\n",
    "    \n",
    "    import re\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    Raw_Data = pd.read_pickle(\"Raw_Data.pkl\")\n",
    "    \n",
    "    with open (\"TF_IDF_Condition_PKL.pkl\" , \"rb\") as TF_IDF_S_C:\n",
    "        TF_IDF_Condition = pickle.load(TF_IDF_S_C)\n",
    "        TF_IDF_S_C.close()\n",
    "\n",
    "###### Function To Process Data\n",
    "    def Data_Processor(Data_):\n",
    "\n",
    "        ### To Lower Case\n",
    "        Data_ = Data_.lower()\n",
    "\n",
    "        ### Removing All The Special Characters or Punctuation\n",
    "        Data_ = re.sub(r'[!|\\|\"|#|$|%|&|(|)|*|+|-|.|/|:|;|<|=|>|?|@|[|]|^|_|`|{|}|~|\\n]' , r'' , Data_)\n",
    "\n",
    "        ### Removing Stop Words & Lemmatisation\n",
    "        stop_words_ = stopwords.words('english')\n",
    "        Word_Lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        All_Words = word_tokenize(Data_)\n",
    "\n",
    "        New_Text = \"\"\n",
    "        for Each_Word in All_Words:\n",
    "            if Each_Word not in stop_words_ and len(Each_Word) > 1:\n",
    "                Lemmatize_Word = Word_Lemmatizer.lemmatize(Each_Word)\n",
    "                New_Text = New_Text + \" \" + Lemmatize_Word\n",
    "\n",
    "        ### Remove Apostrophe & RETURN\n",
    "        return New_Text.replace(\"'\",\"\")\n",
    "        \n",
    "#######################################################################################    \n",
    "        \n",
    "    Search_Words_Token = word_tokenize(str(Data_Processor(String_To_Search)))\n",
    "    \n",
    "    print(f\"Search String:- \\n{String_To_Search}\\n\")\n",
    "    print(f\"Search String Words Token:- \\n{Search_Words_Token}\")\n",
    "    \n",
    "    Query_Weights = {}\n",
    "    \n",
    "    for KEY in TF_IDF_Condition:\n",
    "        \n",
    "        if KEY[1] in Search_Words_Token:\n",
    "            try:\n",
    "                Query_Weights[KEY[0]] += TF_IDF_Condition[KEY]\n",
    "            except:\n",
    "                Query_Weights[KEY[0]] = TF_IDF_Condition[KEY]\n",
    "                \n",
    "    Query_Weights = sorted(Query_Weights.items() , key = lambda x: x[1] , reverse = True)\n",
    "    \n",
    "    Match_Records = []\n",
    "    \n",
    "    for No in Query_Weights[ : Records_To_Show]:\n",
    "        Match_Records.append(No[0])\n",
    "        \n",
    "    print(f\"\\nRow No That Has Been Matched:- \\n{Match_Records}\")\n",
    "    display(Raw_Data.loc[ Match_Records , ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153e6084",
   "metadata": {},
   "source": [
    "# Call Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "965bce1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search String:- \n",
      "cancer bleeding\n",
      "\n",
      "Search String Words Token:- \n",
      "['cancer', 'bleeding']\n",
      "\n",
      "Row No That Has Been Matched:- \n",
      "[17506, 8723, 6301, 812, 3878]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_No</th>\n",
       "      <th>NCT_Id</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Study_Title</th>\n",
       "      <th>Study_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17506</th>\n",
       "      <td>17507</td>\n",
       "      <td>NCT05287048</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "      <td>Evaluation of MCM5 in Postmenopausal Bleeding Patients</td>\n",
       "      <td>Observational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8723</th>\n",
       "      <td>8724</td>\n",
       "      <td>NCT05403203</td>\n",
       "      <td>Placenta Previa Bleeding</td>\n",
       "      <td>Prediction of Bleeding in Placenta Previa</td>\n",
       "      <td>Observational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>6302</td>\n",
       "      <td>NCT05434728</td>\n",
       "      <td>EhlersDanlos Syndrome, EDS, Classical EhlersDanlos Syndrome, Classical EDS cEDS, Hypermobile EhlersDanlos Syndrome, Hypermobile EDS hEDS, Vascular EhlersDanlos Syndrome, Vascular EDS vEDS</td>\n",
       "      <td>Characterization of Bleeding Disorders in EDS</td>\n",
       "      <td>Observational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>813</td>\n",
       "      <td>NCT05506150</td>\n",
       "      <td>Gastro Intestinal Bleeding, Patient Engagement, Family Members</td>\n",
       "      <td>Patient Important Gastrointestinal Bleeding in the ICU</td>\n",
       "      <td>Observational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3879</td>\n",
       "      <td>NCT05464394</td>\n",
       "      <td>Hemorrhage, Bleeding</td>\n",
       "      <td>Peroperative Administration of Tranexamic Acid in RouxenY Gastric Bypass and Oneanastomosis Gastric Bypass</td>\n",
       "      <td>Interventional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Row_No       NCT_Id  \\\n",
       "17506   17507  NCT05287048   \n",
       "8723     8724  NCT05403203   \n",
       "6301     6302  NCT05434728   \n",
       "812       813  NCT05506150   \n",
       "3878     3879  NCT05464394   \n",
       "\n",
       "                                                                                                                                                                                         Condition  \\\n",
       "17506                                                                                                                                                                           Endometrial Cancer   \n",
       "8723                                                                                                                                                                      Placenta Previa Bleeding   \n",
       "6301   EhlersDanlos Syndrome, EDS, Classical EhlersDanlos Syndrome, Classical EDS cEDS, Hypermobile EhlersDanlos Syndrome, Hypermobile EDS hEDS, Vascular EhlersDanlos Syndrome, Vascular EDS vEDS   \n",
       "812                                                                                                                                 Gastro Intestinal Bleeding, Patient Engagement, Family Members   \n",
       "3878                                                                                                                                                                          Hemorrhage, Bleeding   \n",
       "\n",
       "                                                                                                      Study_Title  \\\n",
       "17506                                                      Evaluation of MCM5 in Postmenopausal Bleeding Patients   \n",
       "8723                                                                    Prediction of Bleeding in Placenta Previa   \n",
       "6301                                                                Characterization of Bleeding Disorders in EDS   \n",
       "812                                                        Patient Important Gastrointestinal Bleeding in the ICU   \n",
       "3878   Peroperative Administration of Tranexamic Acid in RouxenY Gastric Bypass and Oneanastomosis Gastric Bypass   \n",
       "\n",
       "           Study_Type  \n",
       "17506   Observational  \n",
       "8723    Observational  \n",
       "6301    Observational  \n",
       "812     Observational  \n",
       "3878   Interventional  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Best_Match_Records(\"cancer bleeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137acc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ba105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b36178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699aebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
